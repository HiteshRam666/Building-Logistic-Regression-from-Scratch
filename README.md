# Building-Logistic-Regression-from-Scratch

Logistic Regression:

![download (2)](https://user-images.githubusercontent.com/116026459/206472962-bab17320-0f19-472e-add9-bedb9ba230ee.png)

Y_hat --> predicted value

X --> Input Variable

w --> weight

b --> bias

Gradient Descent:
Gradient Descent is an optimization algorithm used for minimizing the loss function in various machine learning algorithms. It is used for updating the parameters of the learning model.

w = w - α*dw

b = b - α*db

Learning Rate:
Learning rate is a tuning parameter in an optimization algorithm that determines the step size at each iteration while moving toward a minimum of a loss function.

Derivatives:

![download (5)](https://user-images.githubusercontent.com/116026459/206473163-71087f6f-3f90-4d6b-a231-1d2e168ffbdd.png)
